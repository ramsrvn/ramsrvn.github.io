---
layout: page
title: Experience
permalink: /experience/
---
{::options auto_ids="false" /}

<div class="experience-container">
    <h1>Professional Experience</h1>

    <div class="company">
        <h2><a href="https://www.garmin.com/" target="_blank">Garmin International</a>, Olathe, Kansas</h2>
        
        <div class="role">
            <h3>Senior Software Engineer – Product Security (June 2025 – Present)</h3>
            <ul>
                <li>Architected cloud-native data pipelines integrating telemetry, SBOM, and compliance datasets into an AWS + Databricks Lakehouse, improving analytics accessibility and governance.</li>
                <li>Developed GenAI-based data processing workflows using AWS Bedrock and OpenAI APIs to extract insights from compliance documents, cutting manual review effort by 40%.</li>
                <li>Transformed static analysis findings into AI-driven data pipelines using Databricks and Delta Lake, automating issue categorization and improving remediation efficiency by 30%.</li>
                <li>Designed data lineage and traceability dashboards in Tableau, improving visibility across 250+ product lines.</li>
                <li>Collaborated with governance and compliance teams to build EU RED / CRA-ready data models, enabling structured, auditable reporting.</li>
                <li>Tuned Spark SQL and distributed compute strategies, improving performance 3.2× and saving $120K annually.</li>
                <li>Led enterprise migration of compliance data pipelines to AWS, reducing manual effort 65%.</li>
            </ul>
        </div>

        <div class="role">
            <h3>Software Engineer 2 – Product Security (Jan 2023 – Jun 2025)</h3>
            <ul>
                <li>Engineered ETL and orchestration pipelines processing component, vulnerability, and telemetry data from 1,000+ builds using AWS Glue, Step Functions, and Databricks.</li>
                <li>Built LLM-powered semantic search for querying vulnerability and dependency datasets in natural language.</li>
                <li>Migrated legacy static-analysis results into structured Delta Lake datasets, enabling near-real-time analytics.</li>
                <li>Created a PySpark-based validation framework for schema and data-quality governance across ingestion layers.</li>
                <li>Automated generation of EU RED / CRA compliance datasets and built executive dashboards in Tableau for leadership visibility.</li>
                <li>Mentored peers on data-pipeline design and Databricks best practices.</li>
            </ul>
        </div>
    </div>

    <div class="company">
        <h2><a href="http://www.ensoftcorp.com/" target="_blank">EnSoft Corp.</a>, Ames, Iowa</h2>
        
        <div class="role">
            <h3>Software Engineer (Jan 2019 – Dec 2020)</h3>
            <ul>
                <li>Developed data collection and transformation frameworks to analyze large-scale software builds and code quality metrics.</li>
                <li>Migrated analytics systems from on-prem to AWS S3 / Redshift, cutting batch latency 45%.</li>
                <li>Implemented ETL automation using Python + Spark, improving batch efficiency 40%.</li>
                <li>Built data profiling tools to enhance maintainability and support modernization efforts.</li>
                <li>Automated CI/CD data workflows using Jenkins and Maven.</li>
            </ul>
        </div>

        <div class="role">
            <h3>Software Engineer Intern (May – Aug 2021 & 2022)</h3>
            <ul>
                <li>Evolved internal analytics from scripts to Databricks notebooks with Delta Lake versioning and auditability.</li>
                <li>Introduced Spark streaming for near-real-time build metrics; improved latency/observability of engineering KPIs.</li>
                <li>Prototyped ML-based anomaly detection on build performance data to prioritize defects and trend outliers.</li>
            </ul>
        </div>
    </div>

    <div class="company">
        <h2><a href="https://www.iastate.edu/" target="_blank">Iowa State University</a>, Ames, Iowa</h2>
        
        <div class="role">
            <h3>Visiting Researcher (Jun 2018 – Nov 2018)</h3>
            <ul>
                <li>Contributed to DARPA’s Space/Time Analysis for Cybersecurity (STAC) program, creating data-driven vulnerability analysis tools.</li>
                <li>Designed AI-assisted program analyzers for anomaly detection in C/C++ software.</li>
                <li>Published award-winning research on analytical modeling of security data.</li>
            </ul>
        </div>

        <div class="role">
            <h3>Research & Teaching Assistant (Spring 2021 – Fall 2022)</h3>
            <ul>
                <li>Built an ML-based classifier to identify loop behaviors in Linux kernel code, cutting review time 60%.</li>
                <li>Guided 350+ students on data pipelines, software analytics, and automation.</li>
            </ul>
        </div>
    </div>

    <div class="expertise">
        <h2>Core Expertise</h2>
        <div class="skills">
            <p><strong>Data Engineering & Analytics:</strong> Python (Pandas, PySpark), SQL, Databricks, Spark, Glue, Redshift, EMR, Athena, Tableau, Delta Lake, Airflow</p>
            <p><strong>Cloud Platforms:</strong> AWS (S3, Lambda, RDS, Step Functions, CloudFormation, IAM), Azure (Databricks, Blob Storage)</p>
            <p><strong>AI & ML:</strong> AWS Bedrock, SageMaker, OpenAI APIs, LangChain, Vector DBs (Pinecone, FAISS), NLP Automation</p>
            <p><strong>Security & Compliance:</strong> SBOM, CycloneDX, Vulnerability Analytics, Metadata Pipelines, Governance & Lineage, Regulatory Compliance (EU RED / CRA)</p>
            <p><strong>DevOps & Automation:</strong> Git, Jenkins, Docker, CI/CD Pipelines, JIRA, Jupyter Notebooks</p>
            <p><strong>Programming:</strong> Python, Java, C/C++, SQL, Shell</p>
        </div>
    </div>

    <div class="summary">
        <blockquote>
            <p><strong>Summary:</strong> AWS Certified engineer experienced in bridging <strong>data engineering, AI, and product security</strong>, delivering <strong>secure, scalable, and analytics-ready data platforms</strong> that power intelligence and compliance across enterprise systems.</p>
        </blockquote>
    </div>
</div>
